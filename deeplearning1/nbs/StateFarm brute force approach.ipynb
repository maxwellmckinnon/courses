{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# State Farm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.12 |Anaconda 4.2.0 (64-bit)| (default, Jul  2 2016, 17:42:40) \n",
      "[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sys.version_info(major=2, minor=7, micro=12, releaselevel='final', serial=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)\n",
    "sys.version_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/c/state-farm-distracted-driver-detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```\n",
    "utils/\n",
    "    vgg16.py\n",
    "    utils.py\n",
    "lesson1/\n",
    "    redux.ipynb\n",
    "    data/\n",
    "        redux/\n",
    "            train/\n",
    "                cat.437.jpg\n",
    "                dog.9924.jpg\n",
    "                cat.1029.jpg\n",
    "                dog.4374.jpg\n",
    "            test/\n",
    "                231.jpg\n",
    "                325.jpg\n",
    "                1235.jpg\n",
    "                9923.jpg\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/home/ubuntu/courses/deeplearning1/nbs'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verify we are in the lesson1 directory\n",
    "# Should be .../deeplearning1/nbs\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create references to important directories we will use over and over\n",
    "import os, sys\n",
    "current_dir = os.getcwd()\n",
    "LESSON_HOME_DIR = current_dir\n",
    "DATA_HOME_DIR = current_dir+'/data/statefarm/'\n",
    "DATA_HOME_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '..', '/home/ubuntu/anaconda2/lib/python27.zip', '/home/ubuntu/anaconda2/lib/python2.7', '/home/ubuntu/anaconda2/lib/python2.7/plat-linux2', '/home/ubuntu/anaconda2/lib/python2.7/lib-tk', '/home/ubuntu/anaconda2/lib/python2.7/lib-old', '/home/ubuntu/anaconda2/lib/python2.7/lib-dynload', '/home/ubuntu/anaconda2/lib/python2.7/site-packages', '/home/ubuntu/anaconda2/lib/python2.7/site-packages/Sphinx-1.4.6-py2.7.egg', '/home/ubuntu/anaconda2/lib/python2.7/site-packages/setuptools-27.2.0-py2.7.egg', '/home/ubuntu/anaconda2/lib/python2.7/site-packages/IPython/extensions', '/home/ubuntu/.ipython']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "#Allow relative imports to directories above lesson1/\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "print(sys.path)\n",
    "#import modules\n",
    "from utils import *\n",
    "from vgg16 import Vgg16\n",
    "\n",
    "#Instantiate plotting tool\n",
    "#In Jupyter notebooks, you will need to run this command before doing any plotting\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet50.py\r\n",
      "utils.py\r\n",
      "utils.pyc\r\n",
      "vgg16bn.py\r\n",
      "vgg16bn.pyc\r\n",
      "vgg16.py\r\n",
      "vgg16.pyc\r\n"
     ]
    }
   ],
   "source": [
    "!ls | grep \"\\.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action Plan\n",
    "1. Create Validation and Sample sets\n",
    "2. Rearrange image files into their respective directories \n",
    "3. Finetune and Train model\n",
    "4. Generate predictions\n",
    "5. Validate predictions\n",
    "6. Submit predictions to Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Create validation set and sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm\n",
      "mkdir: cannot create directory ‘valid’: File exists\n",
      "mkdir: cannot create directory ‘results’: File exists\n"
     ]
    }
   ],
   "source": [
    "#Create directories\n",
    "%cd $DATA_HOME_DIR\n",
    "%mkdir valid\n",
    "%mkdir results\n",
    "%mkdir -p sample/train\n",
    "%mkdir -p sample/test\n",
    "%mkdir -p sample/valid\n",
    "%mkdir -p sample/results\n",
    "%mkdir -p test/unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/train\n"
     ]
    }
   ],
   "source": [
    "print(DATA_HOME_DIR)\n",
    "%cd $DATA_HOME_DIR/train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move from training set to validation set - only run these moving file blocks once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/train/c0\n",
      "Total number of files in this subdir: 2489\n",
      "['img_23182.jpg' 'img_29245.jpg' 'img_46818.jpg' 'img_75564.jpg' 'img_22984.jpg']\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/valid/c0/img_23182.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/valid/c0/img_29245.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/train/c1\n",
      "Total number of files in this subdir: 2267\n",
      "['img_1242.jpg' 'img_49674.jpg' 'img_16371.jpg' 'img_6609.jpg' 'img_28270.jpg']\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/valid/c1/img_1242.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/valid/c1/img_49674.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/train/c2\n",
      "Total number of files in this subdir: 2317\n",
      "['img_5784.jpg' 'img_92707.jpg' 'img_95514.jpg' 'img_41946.jpg' 'img_21964.jpg']\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/valid/c2/img_5784.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/valid/c2/img_92707.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/train/c3\n",
      "Total number of files in this subdir: 2346\n",
      "['img_72441.jpg' 'img_87086.jpg' 'img_82302.jpg' 'img_9251.jpg' 'img_34498.jpg']\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/valid/c3/img_72441.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/valid/c3/img_87086.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/train/c4\n",
      "Total number of files in this subdir: 2326\n",
      "['img_45122.jpg' 'img_56272.jpg' 'img_70345.jpg' 'img_61162.jpg' 'img_16762.jpg']\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/valid/c4/img_45122.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/valid/c4/img_56272.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/train/c5\n",
      "Total number of files in this subdir: 2312\n",
      "['img_39084.jpg' 'img_41801.jpg' 'img_43043.jpg' 'img_99681.jpg' 'img_75624.jpg']\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/valid/c5/img_39084.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/valid/c5/img_41801.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/train/c6\n",
      "Total number of files in this subdir: 2325\n",
      "['img_80797.jpg' 'img_89524.jpg' 'img_84165.jpg' 'img_10918.jpg' 'img_88564.jpg']\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/valid/c6/img_80797.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/valid/c6/img_89524.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/train/c7\n",
      "Total number of files in this subdir: 2002\n",
      "['img_102.jpg' 'img_98904.jpg' 'img_48738.jpg' 'img_73032.jpg' 'img_10693.jpg']\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/valid/c7/img_102.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/valid/c7/img_98904.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/train/c8\n",
      "Total number of files in this subdir: 1911\n",
      "['img_76073.jpg' 'img_56111.jpg' 'img_74193.jpg' 'img_19204.jpg' 'img_44369.jpg']\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/valid/c8/img_76073.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/valid/c8/img_56111.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/train/c9\n",
      "Total number of files in this subdir: 2129\n",
      "['img_8026.jpg' 'img_49693.jpg' 'img_16479.jpg' 'img_85449.jpg' 'img_1125.jpg']\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/valid/c9/img_8026.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/valid/c9/img_49693.jpg\n"
     ]
    }
   ],
   "source": [
    "# Move about 1/10 to validation\n",
    "# There are about 2000 pictures per category so move 200 per category to the validation folders\n",
    "VAL_RATIO = .1\n",
    "for subdir, dirs, files in os.walk(os.path.join(DATA_HOME_DIR, 'train/')):\n",
    "    for dirr in sorted(dirs):\n",
    "        # print(subdir, dirr)\n",
    "        fulldir = os.path.join(subdir, dirr)\n",
    "        %cd $fulldir\n",
    "        TOTFILES = len([name for name in os.listdir('.') if os.path.isfile(name)])\n",
    "        print \"Total number of files in this subdir: {}\".format(TOTFILES)\n",
    "        g = glob('*.jpg')\n",
    "        shuf = np.random.permutation(g)\n",
    "        print(shuf[:5])\n",
    "        DEST_VALI = os.path.join(DATA_HOME_DIR, 'valid', dirr)\n",
    "        try: \n",
    "            os.makedirs(DEST_VALI)\n",
    "        except:\n",
    "            pass\n",
    "        for i in range(int(VAL_RATIO*TOTFILES)): \n",
    "            if i < 2:\n",
    "                print os.path.join(DEST_VALI, shuf[i])\n",
    "            os.rename(shuf[i], os.path.join(DEST_VALI, shuf[i]))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/train/c0\n",
      "['img_13585.jpg' 'img_38088.jpg' 'img_13073.jpg' 'img_47700.jpg' 'img_72977.jpg']\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/train/c0/img_13585.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/train/c0/img_38088.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/train/c0/img_13073.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/train/c0/img_47700.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/train/c0/img_72977.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/train/c1\n",
      "['img_4762.jpg' 'img_29506.jpg' 'img_55977.jpg' 'img_49415.jpg' 'img_64954.jpg']\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/train/c1/img_4762.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/train/c1/img_29506.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/train/c1/img_55977.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/train/c1/img_49415.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/train/c1/img_64954.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/train/c2\n",
      "['img_15124.jpg' 'img_90856.jpg' 'img_51411.jpg' 'img_85130.jpg' 'img_101373.jpg']\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/train/c2/img_15124.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/train/c2/img_90856.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/train/c2/img_51411.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/train/c2/img_85130.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/train/c2/img_101373.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/train/c3\n",
      "['img_50402.jpg' 'img_61110.jpg' 'img_89740.jpg' 'img_42862.jpg' 'img_70031.jpg']\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/train/c3/img_50402.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/train/c3/img_61110.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/train/c3/img_89740.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/train/c3/img_42862.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/train/c3/img_70031.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/train/c4\n",
      "['img_49513.jpg' 'img_84406.jpg' 'img_70827.jpg' 'img_92980.jpg' 'img_20497.jpg']\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/train/c4/img_49513.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/train/c4/img_84406.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/train/c4/img_70827.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/train/c4/img_92980.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/train/c4/img_20497.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/train/c5\n",
      "['img_38080.jpg' 'img_98179.jpg' 'img_88051.jpg' 'img_58973.jpg' 'img_85453.jpg']\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/train/c5/img_38080.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/train/c5/img_98179.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/train/c5/img_88051.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/train/c5/img_58973.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/train/c5/img_85453.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/train/c6\n",
      "['img_11726.jpg' 'img_48975.jpg' 'img_80635.jpg' 'img_17200.jpg' 'img_27522.jpg']\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/train/c6/img_11726.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/train/c6/img_48975.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/train/c6/img_80635.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/train/c6/img_17200.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/train/c6/img_27522.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/train/c7\n",
      "['img_14424.jpg' 'img_19759.jpg' 'img_99020.jpg' 'img_87454.jpg' 'img_35344.jpg']\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/train/c7/img_14424.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/train/c7/img_19759.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/train/c7/img_99020.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/train/c7/img_87454.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/train/c7/img_35344.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/train/c8\n",
      "['img_21258.jpg' 'img_82020.jpg' 'img_61907.jpg' 'img_68838.jpg' 'img_17506.jpg']\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/train/c8/img_21258.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/train/c8/img_82020.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/train/c8/img_61907.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/train/c8/img_68838.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/train/c8/img_17506.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/train/c9\n",
      "['img_43792.jpg' 'img_12890.jpg' 'img_30904.jpg' 'img_58749.jpg' 'img_71490.jpg']\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/train/c9/img_43792.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/train/c9/img_12890.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/train/c9/img_30904.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/train/c9/img_58749.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/train/c9/img_71490.jpg\n"
     ]
    }
   ],
   "source": [
    "# Copy sample data to build network architecture off of - save a lot of time\n",
    "\n",
    "for subdir, dirs, files in os.walk(os.path.join(DATA_HOME_DIR, 'train/')):\n",
    "    for dirr in sorted(dirs):\n",
    "        # print(subdir, dirr)\n",
    "        fulldir = os.path.join(subdir, dirr)\n",
    "        %cd $fulldir\n",
    "        g = glob('*.jpg')\n",
    "        shuf = np.random.permutation(g)\n",
    "        print(shuf[:5])\n",
    "        DEST_VALI = os.path.join(DATA_HOME_DIR, 'sample', 'train', dirr)\n",
    "        try: \n",
    "            os.makedirs(DEST_VALI)\n",
    "        except:\n",
    "            pass\n",
    "        for i in range(200): \n",
    "            if i < 2:\n",
    "                print os.path.join(DEST_VALI, shuf[i])\n",
    "            copyfile(shuf[i], os.path.join(DEST_VALI, shuf[i]))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/valid\n"
     ]
    }
   ],
   "source": [
    "%cd $DATA_HOME_DIR/valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/valid/c0\n",
      "['img_86581.jpg' 'img_28578.jpg' 'img_91925.jpg' 'img_78518.jpg' 'img_12772.jpg']\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/valid/c0/img_86581.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/valid/c0/img_28578.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/valid/c1\n",
      "['img_29687.jpg' 'img_53660.jpg' 'img_66825.jpg' 'img_60268.jpg' 'img_33533.jpg']\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/valid/c1/img_29687.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/valid/c1/img_53660.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/valid/c2\n",
      "['img_92876.jpg' 'img_96616.jpg' 'img_100646.jpg' 'img_42211.jpg' 'img_39809.jpg']\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/valid/c2/img_92876.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/valid/c2/img_96616.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/valid/c3\n",
      "['img_4799.jpg' 'img_100691.jpg' 'img_54898.jpg' 'img_63787.jpg' 'img_50087.jpg']\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/valid/c3/img_4799.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/valid/c3/img_100691.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/valid/c4\n",
      "['img_3821.jpg' 'img_16503.jpg' 'img_66156.jpg' 'img_89373.jpg' 'img_22523.jpg']\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/valid/c4/img_3821.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/valid/c4/img_16503.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/valid/c5\n",
      "['img_48282.jpg' 'img_73215.jpg' 'img_60569.jpg' 'img_47959.jpg' 'img_12687.jpg']\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/valid/c5/img_48282.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/valid/c5/img_73215.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/valid/c6\n",
      "['img_43086.jpg' 'img_3263.jpg' 'img_8662.jpg' 'img_42216.jpg' 'img_9164.jpg']\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/valid/c6/img_43086.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/valid/c6/img_3263.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/valid/c7\n",
      "['img_7398.jpg' 'img_32474.jpg' 'img_50242.jpg' 'img_33436.jpg' 'img_18510.jpg']\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/valid/c7/img_7398.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/valid/c7/img_32474.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/valid/c8\n",
      "['img_47144.jpg' 'img_34109.jpg' 'img_36882.jpg' 'img_49772.jpg' 'img_23443.jpg']\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/valid/c8/img_47144.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/valid/c8/img_34109.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/valid/c9\n",
      "['img_35846.jpg' 'img_87236.jpg' 'img_8480.jpg' 'img_68926.jpg' 'img_27576.jpg']\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/valid/c9/img_35846.jpg\n",
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/sample/valid/c9/img_87236.jpg\n"
     ]
    }
   ],
   "source": [
    "# Copy sample data to build network architecture off of - save a lot of time\n",
    "\n",
    "for subdir, dirs, files in os.walk(os.path.join(DATA_HOME_DIR, 'valid/')):\n",
    "    for dirr in sorted(dirs):\n",
    "        # print(subdir, dirr)\n",
    "        fulldir = os.path.join(subdir, dirr)\n",
    "        %cd $fulldir\n",
    "        g = glob('*.jpg')\n",
    "        shuf = np.random.permutation(g)\n",
    "        print(shuf[:5])\n",
    "        DEST_VALI = os.path.join(DATA_HOME_DIR, 'sample', 'valid', dirr)\n",
    "        try: \n",
    "            os.makedirs(DEST_VALI)\n",
    "        except:\n",
    "            pass\n",
    "        for i in range(50): \n",
    "            if i < 2:\n",
    "                print os.path.join(DEST_VALI, shuf[i])\n",
    "            copyfile(shuf[i], os.path.join(DEST_VALI, shuf[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move test files into unknown dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/courses/deeplearning1/nbs/data/statefarm/test\n"
     ]
    }
   ],
   "source": [
    "# Create single 'unknown' class for test set\n",
    "%cd $DATA_HOME_DIR/test\n",
    "%mv *.jpg unknown/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd $DATA_HOME_DIR\n",
    "\n",
    "#Set path to sample/ path if desired\n",
    "path = DATA_HOME_DIR + '/' #'/sample/'\n",
    "test_path = DATA_HOME_DIR + '/test/' #We use all the test data\n",
    "results_path=DATA_HOME_DIR + '/results/'\n",
    "train_path=path + '/train/'\n",
    "valid_path=path + '/valid/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import Vgg16 helper class\n",
    "vgg = Vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set constants. You can experiment with no_of_epochs to improve the model\n",
    "batch_size=64\n",
    "no_of_epochs=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finetune the model\n",
    "batches = vgg.get_batches(train_path, batch_size=batch_size)\n",
    "val_batches = vgg.get_batches(valid_path, batch_size=batch_size*2)\n",
    "vgg.finetune(batches)\n",
    "\n",
    "#Not sure if we set this for all fits\n",
    "# What the hell is this? - find out later\n",
    "vgg.model.optimizer.lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Notice we are passing in the validation dataset to the fit() method\n",
    "#For each epoch we test our model against the validation set\n",
    "# ? Why do this three times? Just to see? There is no dependence etween the epoches in this method is there?\n",
    "latest_weights_filename = None\n",
    "for epoch in range(no_of_epochs):\n",
    "    print \"Running epoch: %d\" % epoch\n",
    "    vgg.fit(batches, val_batches, nb_epoch=1)\n",
    "    latest_weights_filename = 'ft%d.h5' % epoch\n",
    "    vgg.model.save_weights(results_path+latest_weights_filename)\n",
    "print \"Completed %s fit operations\" % no_of_epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Generate Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use our new model to make predictions on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batches, preds = vgg.test(test_path, batch_size = batch_size*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#For every image, vgg.test() generates two probabilities \n",
    "#based on how we've ordered the cats/dogs directories.\n",
    "#It looks like column one is cats and column two is dogs\n",
    "print preds[:5]\n",
    "\n",
    "filenames = batches.filenames\n",
    "print filenames[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#You can verify the column ordering by viewing some images\n",
    "from PIL import Image\n",
    "Image.open(test_path + filenames[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Save our test results arrays so we can use them again later\n",
    "# How does this save array work?\n",
    "save_array(results_path + 'test_preds.dat', preds)\n",
    "save_array(results_path + 'filenames.dat', filenames)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Validate Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras' *fit()* function conveniently shows us the value of the loss function, and the accuracy, after every epoch (\"*epoch*\" refers to one full run through all training examples). The most important metrics for us to look at are for the validation set, since we want to check for over-fitting. \n",
    "\n",
    "- **Tip**: with our first model we should try to overfit before we start worrying about how to reduce over-fitting - there's no point even thinking about regularization, data augmentation, etc if you're still under-fitting! (We'll be looking at these techniques shortly).\n",
    "\n",
    "As well as looking at the overall metrics, it's also a good idea to look at examples of each of:\n",
    "1. A few correct labels at random\n",
    "2. A few incorrect labels at random\n",
    "3. The most correct labels of each class (ie those with highest probability that are correct)\n",
    "4. The most incorrect labels of each class (ie those with highest probability that are incorrect)\n",
    "5. The most uncertain labels (ie those with probability closest to 0.5)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what we can learn from these examples. (In general, this is a particularly useful technique for debugging problems in the model. However, since this model is so simple, there may not be too much to learn at this stage.)\n",
    "\n",
    "Calculate predictions on validation set, so we can find correct and incorrect examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg.model.load_weights(results_path+latest_weights_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_batches, probs = vgg.test(valid_path, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filenames = val_batches.filenames\n",
    "expected_labels = val_batches.classes #0 or 1\n",
    "\n",
    "#Round our predictions to 0/1 to generate labels\n",
    "our_predictions = probs[:,0]\n",
    "our_labels = np.round(1-our_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "#Helper function to plot images by index in the validation set \n",
    "#Plots is a helper function in utils.py\n",
    "def plots_idx(idx, titles=None):\n",
    "    plots([image.load_img(valid_path + filenames[i]) for i in idx], titles=titles)\n",
    "    \n",
    "#Number of images to view for each visualization task\n",
    "n_view = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. A few correct labels at random\n",
    "correct = np.where(our_labels==expected_labels)[0]\n",
    "print \"Found %d correct labels\" % len(correct)\n",
    "idx = permutation(correct)[:n_view]\n",
    "plots_idx(idx, our_predictions[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. A few incorrect labels at random\n",
    "incorrect = np.where(our_labels!=expected_labels)[0]\n",
    "print \"Found %d incorrect labels\" % len(incorrect)\n",
    "idx = permutation(incorrect)[:n_view]\n",
    "plots_idx(idx, our_predictions[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3a. The images we most confident were cats, and are actually cats\n",
    "correct_cats = np.where((our_labels==0) & (our_labels==expected_labels))[0]\n",
    "print \"Found %d confident correct cats labels\" % len(correct_cats)\n",
    "most_correct_cats = np.argsort(our_predictions[correct_cats])[::-1][:n_view]\n",
    "plots_idx(correct_cats[most_correct_cats], our_predictions[correct_cats][most_correct_cats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3b. The images we most confident were dogs, and are actually dogs\n",
    "correct_dogs = np.where((our_labels==1) & (our_labels==expected_labels))[0]\n",
    "print \"Found %d confident correct dogs labels\" % len(correct_dogs)\n",
    "most_correct_dogs = np.argsort(our_predictions[correct_dogs])[:n_view]\n",
    "plots_idx(correct_dogs[most_correct_dogs], our_predictions[correct_dogs][most_correct_dogs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4a. The images we were most confident were cats, but are actually dogs\n",
    "incorrect_cats = np.where((our_labels==0) & (our_labels!=expected_labels))[0]\n",
    "print \"Found %d incorrect cats\" % len(incorrect_cats)\n",
    "if len(incorrect_cats):\n",
    "    most_incorrect_cats = np.argsort(our_predictions[incorrect_cats])[::-1][:n_view]\n",
    "    plots_idx(incorrect_cats[most_incorrect_cats], our_predictions[incorrect_cats][most_incorrect_cats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4b. The images we were most confident were dogs, but are actually cats\n",
    "incorrect_dogs = np.where((our_labels==1) & (our_labels!=expected_labels))[0]\n",
    "print \"Found %d incorrect dogs\" % len(incorrect_dogs)\n",
    "if len(incorrect_dogs):\n",
    "    most_incorrect_dogs = np.argsort(our_predictions[incorrect_dogs])[:n_view]\n",
    "    plots_idx(incorrect_dogs[most_incorrect_dogs], our_predictions[incorrect_dogs][most_incorrect_dogs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. The most uncertain labels (ie those with probability closest to 0.5).\n",
    "most_uncertain = np.argsort(np.abs(our_predictions-0.5))\n",
    "plots_idx(most_uncertain[:n_view], our_predictions[most_uncertain])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps the most common way to analyze the result of a classification model is to use a [confusion matrix](http://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/). Scikit-learn has a convenient function we can use for this purpose:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(expected_labels, our_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can just print out the confusion matrix, or we can show a graphical view (which is mainly useful for dependents with a larger number of categories)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm, val_batches.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit Predictions to Kaggle!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the format Kaggle requires for new submissions:\n",
    "```\n",
    "imageId,isDog\n",
    "1242, .3984\n",
    "3947, .1000\n",
    "4539, .9082\n",
    "2345, .0000\n",
    "```\n",
    "\n",
    "Kaggle wants the imageId followed by the probability of the image being a dog. Kaggle uses a metric called [Log Loss](http://wiki.fast.ai/index.php/Log_Loss) to evaluate your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load our test predictions from file\n",
    "preds = load_array(results_path + 'test_preds.dat')\n",
    "filenames = load_array(results_path + 'filenames.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Grab the dog prediction column\n",
    "isdog = preds[:,1]\n",
    "print \"Raw Predictions: \" + str(isdog[:5])\n",
    "print \"Mid Predictions: \" + str(isdog[(isdog < .6) & (isdog > .4)])\n",
    "print \"Edge Predictions: \" + str(isdog[(isdog == 1) | (isdog == 0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Log Loss](http://wiki.fast.ai/index.php/Log_Loss) doesn't support probability values of 0 or 1--they are undefined (and we have many). Fortunately, Kaggle helps us by offsetting our 0s and 1s by a very small value. So if we upload our submission now we will have lots of .99999999 and .000000001 values. This seems good, right?\n",
    "\n",
    "Not so. There is an additional twist due to how log loss is calculated--log loss rewards predictions that are confident and correct (p=.9999,label=1), but it punishes predictions that are confident and wrong far more (p=.0001,label=1). See visualization below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize Log Loss when True value = 1\n",
    "#y-axis is log loss, x-axis is probabilty that label = 1\n",
    "#As you can see Log Loss increases rapidly as we approach 0\n",
    "#But increases slowly as our predicted probability gets closer to 1\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "x = [i*.0001 for i in range(1,10000)]\n",
    "y = [log_loss([1],[[i*.0001,1-(i*.0001)]],eps=1e-15) for i in range(1,10000,1)]\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.axis([-.05, 1.1, -.8, 10])\n",
    "plt.title(\"Log Loss when true label = 1\")\n",
    "plt.xlabel(\"predicted probability\")\n",
    "plt.ylabel(\"log loss\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#So to play it safe, we use a sneaky trick to round down our edge predictions\n",
    "#Swap all ones with .95 and all zeros with .05\n",
    "isdog = isdog.clip(min=0.05, max=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Extract imageIds from the filenames in our test/unknown directory \n",
    "filenames = batches.filenames\n",
    "ids = np.array([int(f[8:f.find('.')]) for f in filenames])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we join the two columns into an array of [imageId, isDog]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "subm = np.stack([ids,isdog], axis=1)\n",
    "subm[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%cd $DATA_HOME_DIR\n",
    "submission_file_name = 'submission1.csv'\n",
    "np.savetxt(submission_file_name, subm, fmt='%d,%.5f', header='id,label', comments='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "%cd $LESSON_HOME_DIR\n",
    "FileLink(DATA_HOME_DIR+'/'+submission_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can download this file and submit on the Kaggle website or use the Kaggle command line tool's \"submit\" method."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "nav_menu": {},
  "nbpresent": {
   "slides": {
    "28b43202-5690-4169-9aca-6b9dabfeb3ec": {
     "id": "28b43202-5690-4169-9aca-6b9dabfeb3ec",
     "prev": null,
     "regions": {
      "3bba644a-cf4d-4a49-9fbd-e2554428cf9f": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "f3d3a388-7e2a-4151-9b50-c20498fceacc",
        "part": "whole"
       },
       "id": "3bba644a-cf4d-4a49-9fbd-e2554428cf9f"
      }
     }
    },
    "8104def2-4b68-44a0-8f1b-b03bf3b2a079": {
     "id": "8104def2-4b68-44a0-8f1b-b03bf3b2a079",
     "prev": "28b43202-5690-4169-9aca-6b9dabfeb3ec",
     "regions": {
      "7dded777-1ddf-4100-99ae-25cf1c15b575": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "fe47bd48-3414-4657-92e7-8b8d6cb0df00",
        "part": "whole"
       },
       "id": "7dded777-1ddf-4100-99ae-25cf1c15b575"
      }
     }
    }
   },
   "themes": {}
  },
  "toc": {
   "nav_menu": {
    "height": "148px",
    "width": "254px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
